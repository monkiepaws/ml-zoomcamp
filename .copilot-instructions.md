# Copilot Instructions for ML Zoomcamp Project

## Project Context
This is a machine learning course project for the Data Talks ML Zoomcamp 2025. The project consists of activities and homework assignments focused on practical machine learning implementation using Python and Jupyter notebooks.

## Code Style and Conventions

### Python Code
- Follow PEP 8 style guidelines
- Use consistent string quote style throughout the project (single quotes preferred for this project)
- Use descriptive variable names, especially for datasets and models
- Add docstrings to functions that perform data processing or model training
- Use type hints for function parameters and return values where appropriate
- Prefer pandas for data manipulation and numpy for numerical operations

### Jupyter Notebooks
- Start each notebook with a clear title and description in markdown
- Use markdown cells to explain the purpose of each section
- Include comments in code cells to explain complex operations
- Show intermediate results and visualizations to demonstrate understanding
- End notebooks with conclusions or key takeaways

## Machine Learning Workflow

### Data Exploration and Preprocessing
- Always start with data.shape, data.info(), and data.describe()
- Check for missing values and handle them appropriately
- Create visualizations to understand data distributions
- Perform feature engineering when relevant
- Split data into train/validation/test sets early in the process

### Model Development
- Start with simple baseline models before complex ones
- Use cross-validation for model evaluation
- Implement proper evaluation metrics (accuracy, precision, recall, F1, RMSE, etc.)
- Compare multiple models and document performance
- Use scikit-learn conventions for model fitting and prediction

### Code Structure
- Import all libraries at the top of notebooks
- Define reusable functions for repetitive tasks
- Use consistent naming for variables:
  - `X` for features, `y` for target variables
  - `X_train`, `X_val`, `X_test` for split datasets
  - `model` or descriptive names for trained models
  - `y_pred` for predictions

## Common Libraries and Usage Patterns

### Standard Imports
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
```

### Data Loading and Exploration
- Use `pd.read_csv()` for CSV files
- Always check data types with `dtypes`
- Use `value_counts()` for categorical variables
- Create correlation matrices for numerical features

### Visualization Preferences
- Use seaborn for statistical plots
- Use matplotlib for custom visualizations
- Always include titles, axis labels, and legends
- Use appropriate color schemes and figure sizes

### Model Training Patterns
- Always set random_state for reproducibility
- Use fit/transform pattern for preprocessing
- Validate models using appropriate metrics
- Save important results and model parameters

## Homework and Assignment Guidelines

### Documentation
- Include clear problem statements at the beginning
- Document assumptions and design decisions
- Explain the reasoning behind model choices
- Provide interpretation of results and metrics

### Code Quality
- Write clean, readable code that can be easily reviewed
- Include error handling for data loading and processing
- Use meaningful variable names that reflect the problem domain
- Comment on any non-obvious data transformations

### Reproducibility
- Set random seeds for all random operations
- Include package versions in comments when relevant
- Make file paths relative to project root
- Document any manual data preparation steps

## Problem-Specific Guidance

### Classification Problems
- Always check class distribution and handle imbalanced datasets
- Use appropriate evaluation metrics (not just accuracy)
- Include confusion matrices and classification reports
- Consider feature importance analysis

### Regression Problems
- Plot residuals to check model assumptions
- Use multiple evaluation metrics (RMSE, MAE, RÂ²)
- Check for outliers and their impact on models
- Visualize predictions vs actual values

### Feature Engineering
- Document the reasoning behind new features
- Check feature correlations before adding engineered features
- Validate that engineered features improve model performance
- Consider feature scaling and normalization

## DevContainer Considerations
- Assume all required packages are available as per requirements.txt
- Use relative paths for data files within the project
- Leverage the containerized environment for consistent results
- Consider using pickle or joblib for saving trained models

## Learning Objectives
When suggesting code, prioritize:
1. Educational value and clarity over optimization
2. Following machine learning best practices
3. Demonstrating proper workflow and methodology
4. Encouraging experimentation and iteration
5. Building understanding of underlying concepts

Remember: This is a learning environment. Prioritize code that helps understand machine learning concepts and workflows rather than just achieving the best performance.
